{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6ad6387-02f8-43e0-a6c2-5f424de9187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "from opencc import OpenCC\n",
    "from tqdm.auto import tqdm\n",
    "from stanza.server import CoreNLPClient\n",
    "from stanford_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec93d357-0f20-409c-ace8-9e92a011eaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CORENLP_HOME\"] = os.path.expanduser(\"~/etc/stanford-corenlp-4.4.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97debd7b-3104-4dbd-9d14-2979cc4c2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/qsylls_fasttext.csv\", \"r\") as fin:\n",
    "    qsylls = fin.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efde1bb8-0a4c-4bb7-a6f6-c84f949c4bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_iter = iter(qsylls)\n",
    "batch_iter = iter(lambda: list(islice(qs_iter, 3)), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbaca049-b78c-40ae-90cf-df2101c7f4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['非會員試\\n', '平方公里\\n', '中華民國\\n'],\n",
       " ['澳大利亚\\n', '社会主义\\n', '另一方面\\n'],\n",
       " ['马来西亚\\n', '维基百科\\n', '除此之外\\n'],\n",
       " ['巴基斯坦\\n', '与此同时\\n', '阿里巴巴\\n'],\n",
       " ['為輻鰭魚\\n', '免費視訊\\n', '奥林匹克\\n'],\n",
       " ['不好意思\\n', '绝大多数\\n', '哥伦比亚\\n'],\n",
       " ['翻譯而來\\n', '各种各样\\n', '也就是说\\n'],\n",
       " ['黑龙江省\\n', '前所未有\\n', '第二十一\\n'],\n",
       " ['共产主义\\n', '火影忍者\\n', '资本主义\\n'],\n",
       " ['第二十二\\n', '搜尋關鍵\\n', '第二十三\\n']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(batch_iter, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38274d0c-549e-4f72-9c0c-ca63218dd5bf",
   "metadata": {},
   "source": [
    "## Simple Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ee95ba-408e-432a-8477-d2238541877e",
   "metadata": {},
   "source": [
    "## Select NP compounds from four-char words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4cdca-36eb-4f0f-a99a-9cff0b826d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs_iter = iter(qsylls)\n",
    "batch_size = 10\n",
    "batch_iter = iter(lambda: list(islice(qs_iter, batch_size)), [])\n",
    "t2s = OpenCC('t2s.json')\n",
    "\n",
    "np_compounds = []\n",
    "with CoreNLPClient(properties=\"chinese\",\n",
    "        annotators=['tokenize','ssplit','pos','parse'],\n",
    "        timeout=30000,        \n",
    "        memory='6G', be_quiet=True) as client:    \n",
    "    for qs_list in tqdm(batch_iter):\n",
    "        qs_sen = \"。\".join(x.strip() for x in qs_list)\n",
    "        ann = client.annotate(t2s.convert(qs_sen))\n",
    "        for qs_x, sent_x in zip(qs_list, ann.sentence):\n",
    "            np_nodes = get_nodes(sent_x.parseTree, is_np_compound)            \n",
    "            if np_nodes:\n",
    "                npcs = flatten_compound(np_nodes[0])\n",
    "                np_compounds.append(npcs)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2fe8572-15c8-4eca-84cb-e6c07cf65a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42471"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np_compounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e73a7dc7-119a-43d4-9b0e-3e799cd70f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/fasttext_compounds.csv\", \"w\") as fout:\n",
    "    for np_x, pos_x in np_compounds:\n",
    "        if all(len(x)==2 for x in np_x):\n",
    "            fout.write(f\"{','.join(np_x)},{','.join(pos_x)}\\n\")\n",
    "\n",
    "with open(\"../data/fasttext_compounds_nn2.csv\", \"w\") as fout:\n",
    "    for np_x, pos_x in np_compounds:\n",
    "        if any(x!=\"NN\" for x in pos_x):\n",
    "            continue\n",
    "        if all(len(x)==2 for x in np_x):\n",
    "            fout.write(f\"{','.join(np_x)},{','.join(pos_x)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0ae77db-9462-4279-a58b-9a7417b0a091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"264px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,80.0,264.0\" width=\"80px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">ROOT</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">IP</text></svg><svg width=\"60%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">QP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">CLP</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">M</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">平方公里</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"40%\" x=\"60%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">PU</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">。</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"80%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
      ],
      "text/plain": [
       "TreeLayout(('ROOT', ('IP', ('QP', ('CLP', ('M', '平方公里'))), ('PU', '。'))))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import svgling\n",
    "svgling.draw_tree(to_linear(ann.sentence[1].parseTree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9dc94-78eb-46e6-aebc-b5ff08a7fffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
